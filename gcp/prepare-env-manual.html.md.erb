---
title: Preparing to Deploy Ops Manager on GCP Manually
owner: Ops Manager
iaas: GCP
---

This topic describes the preparation steps required to install Ops Manager for Pivotal Cloud Foundry (PCF) on Google Cloud Platform (GCP).


## <a id="prerequisites"></a> Prerequisites

Before you prepare your Ops Manager installation, do the following depending on the runtime you intend to deploy:

- If you are deploying Pivotal Application Service (PAS), see [PCF on GCP Requirements](https://docs.pivotal.io/pivotalcf/<%= product_info['local_product_version'].to_s.sub('.','-') %>/customizing/gcp.html).

- If you are deploying <%= vars.pks_product_full%>, see [GCP Prerequisites and Resource Requirements](https://docs.pivotal.io/runtimes/pks/gcp-requirements.html).


## <a id="config-components"></a> Configuration and Components

This section outlines high-level infrastructure options for PCF on GCP. A PCF deployment includes Ops Manager and your chosen runtime. For example, both Ops Manager with PAS
and Ops Manager with <%= vars.pks_product_short%> are PCF deployments. For more information, review the deployment
options and recommendations in [Reference Architecture for Pivotal Cloud Foundry on GCP](https://docs.pivotal.io/pivotalcf/<%= product_info['local_product_version'].to_s.sub('.','-') %>/refarch/gcp/gcp_ref_arch.html).

You can deploy PCF using one of two main configurations on a GCP virtual private cloud (VPC):

  * A _single-project_ configuration that gives Ops Manager full access to VPC resources
  * A _shared VPC_ configuration in which Ops Manager shares VPC resources

See [Shared vs Single-Project VPCs](https://docs.pivotal.io/pivotalcf/<%= product_info['local_product_version'].to_s.sub('.','-') %>/refarch/gcp/gcp_ref_arch.html#shared-vs-single) in the _Reference Architecture for Pivotal Cloud Foundry on GCP_ topic for a full discussion and recommendations.

When deploying PCF on GCP, Pivotal recommends using the following GCP components:

  * [Google Cloud SQL](https://cloud.google.com/sql/docs/) for external database services
  * [NAT Gateway Instances](https://cloud.google.com/solutions/connecting-securely#natgateway) to limit the number of VMs with public IP addresses
  * [Google Cloud Storage](https://cloud.google.com/storage/) for external file storage


## <a id="iam_account"></a> Step 1: Set up IAM Service Accounts

Ops Manager uses IAM service accounts to access GCP resources.

**For a single-project installation**: Complete the following steps to create a service account for Ops Manager.

**For a shared-VPC installation**: Complete the following steps twice, to create a host account and service account for Ops Manager.

1. From the GCP console, select **IAM & Admin**, then **Service accounts**.

1. Click **Create Service Account**:
  * **Service account name**: Enter a name. For example, `bosh`.
  * **Role**: Select the following roles:
        * **Service Accounts > Service Account User**
        * **Service Accounts > Service Account Token Creator**
        * **Compute Engine > Compute Instance Admin (v1)**
        * **Compute Engine > Compute Network Admin**
        * **Compute Engine > Compute Storage Admin**
        * **Storage > Storage Admin**
        <p class="note"><strong>Note:</strong> You must scroll down in the pop-up windows to select all required roles.<br><br>
        The <strong>Service Account User</strong> role is only required if you plan to use <strong>The Ops Manager VM Service Account</strong> to deploy Ops Manager. For more information about <strong>The Ops Manager VM Service Account</strong>, see <a href="config-manual.html#gcp-config">Step 2: Google Cloud Platform Config</a> in <em>Configuring BOSH Director on GCP</em>.</p>
  * **Service account ID**: The field automatically generates a unique ID based on the username.
  * **Furnish a new private key**: Select this checkbox and JSON as the **Key type**.
    <%= image_tag("../common/images/gcp/iam_account_2.png") %>

1. Click **Create**. Your browser automatically downloads a JSON file with a private key for this account. Save this file in a secure location.

<p class='note'><strong>Note:</strong> You can use this service account to configure file storage for PAS. For more information, see the <a href="https://docs.pivotal.io/pivotalcf/<%= product_info['local_product_version'].to_s.sub('.','-') %>/customizing/pas-file-storage.html#gcp">GCP</a> section of the <em>Configuring File Storage for PAS</em> topic.</p>


## <a id="enable_compute_resource_api"></a> Step 2: Enable Google Cloud APIs

Ops Manager manages GCP resources using the Google Compute Engine and Cloud Resource Manager APIs. To enable these APIs, do the following:

1. Log in to the Google Developers Console at [https://console.developers.google.com](https://console.developers.google.com).

1. In the console, navigate to the GCP projects where you want to install Ops Manager.
  - For a single-project installation, complete the following steps for the Ops Manager project.
  - For a shared-VPC installation, complete the following steps for both host and service projects, to enable them to access the Google Cloud API.

1. Select **API Manager > Library**.

1. Under **Google Cloud APIs**, select **Compute Engine API**.

1. On the **Google Compute Engine API** page, click **Enable**.

1. In the search field, enter `Google Cloud Resource Manager API`.

1. On the **Google Cloud Resource Manager API** page, click **Enable**.

1. To verify that the APIs have been enabled, perform the following steps:
    1. Log in to GCP using the IAM service account you created in [Set up IAM Service Accounts](#iam_account):
     <pre class="terminal">
     $ gcloud auth activate-service-account --key-file JSON_KEY_FILENAME
     </pre>

  1. List your projects:
    <pre class="terminal">
    $ gcloud projects list
    PROJECT_ID              NAME                      PROJECT_NUMBER
    my-host-project-id      my-host-project-name      ##############
    my-service-project-id   my-service-project-name   ##############
    </pre>
    This command lists the projects where you enabled Google Cloud APIs.


## <a id="create_network"></a> Step 3: Create a GCP Network with Subnets

1. Log in to the [GCP console](https://console.cloud.google.com/).

1. Navigate to the GCP project where you want to install Ops Manager. For a shared-VPC installation, navigate to the host project.

1. Select **VPC network**, then **CREATE VPC NETWORK**.
  ![Create VPC Network](../common/images/gcp/gcp-vpc-networks.png)

1. In the **Name** field, enter a name of your choice for the VPC network. This name helps you identify resources for this deployment in the GCP console. Network names must be lowercase. For example, `pcf-virt-net`.<br>
    ![Enter VPC Name](../common/images/gcp/gcp-vpc-name.png)
  1. Under **Subnets**, complete the form as follows to create an infrastructure subnet for Ops Manager and NAT instances:
      <table>
        <tr>
          <th style="width:22%">Name</th>
          <td><code>pcf-infrastructure-subnet-GCP-REGION</code><br>
          Example: <code>pcf-infrastructure-subnet-us-west1</code></td>
        </tr>
        <tr>
          <th>Region</th>
          <td>A region that supports three availability zones. For help selecting the correct region for your deployment,
            see the <a href="https://cloud.google.com/compute/docs/regions-zones/regions-zones">Google documentation about regions and zones</a>.</td>
        </tr>
        <tr>
        <th>IP address range</th>
        <td>A CIDR ending in <code>/26</code><br>
        Example: <code>192.168.101.0/26</code></td>
        </tr>
      </table><br>
      See the following image for an example:
      ![Create VPC Subnet](../common/images/gcp/gcp-vpc-subnet.png)
      <p class="note"><strong>Note:</strong> For deployments that do not use external IP addresses, enable <strong>Private Google access</strong> to allow your runtime to make API calls to Google services.</p>
    1. Click **Add subnet** to add a second subnet for the BOSH Director and components specific to your runtime. Complete the form as follows:
      <table>
        <tr>
          <th style="width:25%">Name</th>
          <td><code>pcf-RUNTIME-subnet-GCP-REGION</code><br>
          Example: <code>pcf-pas-subnet-us-west1</code></td>
        </tr>
        <tr>
          <th>Region</th>
          <td>The same region you selected for the infrastructure subnet</td>
        </tr>
        <tr>
        <th>IP address range</th>
        <td>A CIDR ending in <code>/22</code><br>
            Example: <code>192.168.16.0/22</code></td>
        </tr>
      </table><br>
    1. Click **Add subnet** to add a third **Subnet** with the following details:
      <table>
        <tr>
          <th style="width:25%">Name</th>
          <td><code>pcf-services-subnet-GCP-REGION</code><br>
          Example: <code>pcf-services-subnet-us-west1</code></td>
        </tr>
        <tr>
          <th>Region</th>
          <td>The same region you selected for the previous subnets</td>
        </tr>
        <tr>
        <th>IP address range</th>
        <td>A CIDR in <code>/22</code><br>
            Example: <code>192.168.20.0/22</code></td>
        </tr>
      </table><br>
      See the following image for an example:
      ![Subnetworks Example](../common/images/gcp/vpc_subnetworks.png)

1. Under **Dynamic routing mode**, leave **Regional** selected.

1. Click **Create**.


## <a id="create_nat"></a> Step 4: Create NAT Instances

Use NAT instances when you want to expose only a minimal number of public IP addresses.

Creating NAT instances permits internet access from cluster VMs.
You might, for example, need this internet access for pulling Docker images or enabling internet access for your workloads.

For more information, see [Reference Architecture for Pivotal Cloud Foundry on GCP](https://docs.pivotal.io/pivotalcf/<%= product_info['local_product_version'].to_s.sub('.','-') %>/refarch/gcp/gcp_ref_arch.html#common_network) and [GCP documentation](https://cloud.google.com/solutions/connecting-securely#natgateway).

1. In the GCP console, with your single project or shared-VPC host project selected, navigate to **Compute Engine** > **VM instances**.
  ![Compute Instance](../common/images/gcp/gcp-vm-instances.png)

1. Click **CREATE INSTANCE**.
  ![Create Instance](../common/images/gcp/gcp-vm-create.png)

1. Complete the following fields:
  * **Name**: Enter `pcf-nat-gateway-pri`. <br>
    This is the first, or primary, of three NAT instances you need.
    If you use a single AZ, you need only one NAT instance.
  * **Zone**: Select the first zone from your region.<br>
    Example: For region `us-west1`, select zone `us-west1-a`.
  * **Machine type**: Select `n1-standard-4`.
  * **Boot disk**: Click **Change** and select `Ubuntu 14.04 LTS`.
  <br>
  ![Primary Nat Example](../common/images/gcp/gcp-primary-nat.png)

1. Expand the additional configuration fields by clicking **Management, disks, networking, SSH keys**.<br>
  ![Management dropdown](../common/images/gcp/gcp-nat-dropdown.png)
  1. In the **Startup script** field under **Automation**, enter the following text:
      <code>#! /bin/bash<br>
      sudo sysctl -w net.ipv4.ip_forward=1<br>
      sudo sh -c 'echo net.ipv4.ip_forward=1 >> /etc/sysctl.conf'<br>
      sudo iptables -t nat -A POSTROUTING -o eth0 -j MASQUERADE</code>
      ![Startup Script](../common/images/gcp/gcp-nat-startup.png)

1. Click **Networking** to open additional network configuration fields:
  ![NAT Networking settings](../common/images/gcp/gcp-nat-network.png)
    1. In the **Network tags** field, add the following: `nat-traverse` and `pcf-nat-instance`.
    1. Click on the **Networking** tab and the pencil icon to edit the **Network interface**.
    1. For **Network**, select `pcf-virt-net`. You created this network in [Step 1: Create a GCP Network with Subnets](#create-net).
    1. For **Subnetwork**, select `pcf-infrastructure-subnet-GCP-REGION`.
    1. For **Primary internal IP**, select `Ephemeral (Custom)`. Enter an IP address, for example, `192.168.101.2`, in the **Custom ephemeral IP address** field. The IP address must meet the following requirements:
      - The IP address must exist in the CIDR range you set for the `pcf-infrastructure-subnet-GCP-REGION` subnet.
      - The IP address must exist in a reserved IP range set later in BOSH Director. The reserved range is typically the first `.1` through `.9` addresses in the CIDR range you set for the `pcf-infrastructure-subnet-GCP-REGION` subnet.
      - The IP address cannot be the same as the Gateway IP address set later in Ops Manager. The Gateway IP address is typically the first `.1` address in the CIDR range you set for the `pcf-infrastructure-subnet-GCP-REGION` subnet.
    1. For **External IP**, select `Ephemeral`.
    <p class="note"><strong>Note</strong>: If you select a static external IP address for the NAT instance, then you can use the static IP to further secure access to your CloudSQL instances.</p>
    1. Set **IP forwarding** to `On`.
    1. Click **Done**.

1. Click **Create** to finish creating the NAT instance.

1. Repeat steps 2-6 to create two additional NAT instances with the names and zones specified in the table below. The rest of the configuration remains the same.
    <table>
      <tr>
        <th rowspan="3" width="15%">Instance 2</th>
        <td width="15%"><strong>Name</strong></td>
        <td>
          <code>pcf-nat-gateway-sec</code>
        </td>
      </tr>
      <tr>
        <td><strong>Zone</strong></td>
        <td>
          Select the second zone from your region.<br>
          Example: For region <code>us-west1</code>, select zone <code>us-west1-b</code>.<br>
        </td>
      </tr>
      <tr>
        <td><strong>Internal IP</strong></td>
        <td>
          Select <code>Custom</code> and enter an IP address in the <strong>Internal IP address</strong> field. Example: <code>192.168.101.3</code>.
          <br><br>As described above, this address must in the CIDR range you set for the <code>pcf-infrastructure-subnet-GCP-REGION</code> subnet, must exist in a reserved IP range set later in BOSH Director, and cannot be the same as the Gateway IP address set later in Ops Manager.
        </td>
      </tr>
      <tr>
        <th rowspan="3">Instance 3</th>
        <td><strong>Name</strong></td>
        <td>
          <code>pcf-nat-gateway-ter</code>
        </td>
      </tr>
      <tr>
        <td><strong>Zone</strong></td>
        <td>
          Select the third zone from your region.<br>
          Example: For region <code>us-west1</code>, select zone <code>us-west1-c</code>.
        </td>
      </tr>
      <tr>
        <td><strong>Internal IP</strong></td>
        <td>
          Select <code>Custom</code> and enter an IP address in the <strong>Internal IP address</strong> field. Example: <code>192.168.101.4</code>.
          <br><br>As described above, this address must in the CIDR range you set for the <code>pcf-infrastructure-subnet-GCP-REGION</code> subnet, must exist in a reserved IP range set later in BOSH Director, and cannot be the same as the Gateway IP address set later in Ops Manager.
        </td>
      </tr>
    </table>

### <a id="nat-routes"></a> Create Routes for NAT Instances

1. Navigate to **VPC Networks** > **Routes**.
  ![NAT Routes](../common/images/gcp/gcp-vpc-routes.png)

1. Click **CREATE ROUTE**.

1. Complete the form as follows:
  * **Name**: `pcf-nat-pri`
  * **Network**: `pcf-virt-net`
  * **Destination IP range**: `0.0.0.0/0`
  * **Priority**: `800`
  * **Instance tags**: `pcf`
  * **Next hop**: `Specify an instance`
  * **Next hop instance**: `pcf-nat-gateway-pri`

1. Click **Create** to finish creating the route.

1. Repeat steps 2-4 to create two additional routes with the names and next hop instances specified in the table below. The rest of the configuration remains the same.
  <table>
    <tr>
      <th>Route 2</th>
      <td>
        <strong>Name</strong>: <code>pcf-nat-sec</code><br>
        <strong>Next hop instance</strong>: <code>pcf-nat-gateway-sec</code>
      </td>
    </tr>
    <tr>
      <th>Route 3</th>
      <td>
        <strong>Name</strong>: <code>pcf-nat-ter</code><br>
        <strong>Next hop instance</strong>: <code>pcf-nat-gateway-ter</code>
      </td>
    </tr>
    </table>


## <a id="firewall_rules"></a> Step 5: Create Firewall Rules for the Network

GCP lets you assign tags to VM instances and create firewall rules that apply to VMs based on their tags. For more information about tags, see [Labeling Resources](https://cloud.google.com/compute/docs/labeling-resources) in the Google Cloud documentation.
This step assigns tags and firewall rules to Ops Manager components and VMs that handle incoming traffic.

1. With your single project or shared-VPC host project selected, navigate to the **Networking** > **VPC network** pane and select **Firewall rules**.

1. Apply the firewall rules in the following table:
       <table>
        <tr><th colspan="2" style="text-align: center;">Firewall Rules</th></tr>
          <tr>
            <th>Rule 1</th>
            <td>
              This rule allows SSH from public networks.<br><br>
              <strong>Name</strong>: <code>pcf-allow-ssh</code><br>
              <strong>Network</strong>: <code>pcf-virt-net</code><br>
              <strong>Allowed protocols and ports</strong>: <code>tcp:22</code><br>
              <strong>Source filter</strong>: IP ranges<br>
              <strong>Source IP ranges</strong>: <code>0.0.0.0/0</code><br>
              <strong>Target tags</strong>: <code>allow-ssh</code>
            </td>
          </tr>
          <tr>
            <th>Rule 2</th>
            <td>
              This rule allows HTTP from public networks.<br><br>
              <strong>Name</strong>: <code>pcf-allow-http</code><br>
              <strong>Network</strong>: <code>pcf-virt-net</code><br>
              <strong>Allowed protocols and ports</strong>: <code>tcp:80</code><br>
              <strong>Source filter</strong>: IP ranges<br>
              <strong>Source IP ranges</strong>: <code>0.0.0.0/0</code><br>
              <strong>Target tags</strong>: <code>allow-http</code>, <code>router</code>
            </td>
          </tr>
          <tr>
            <th>Rule 3</th>
            <td>
              This rule allows HTTPS from public networks.<br><br>
              <strong>Name</strong>: <code>pcf-allow-https</code><br>
              <strong>Network</strong>: <code>pcf-virt-net</code><br>
              <strong>Allowed protocols and ports</strong>: <code>tcp:443</code><br>
              <strong>Source filter</strong>: IP ranges<br>
              <strong>Source IP ranges</strong>: <code>0.0.0.0/0</code><br>
              <strong>Target tags</strong>: <code>allow-https</code>, <code>router</code>
            </td>
          </tr>
          <tr>
            <th>Rule 4</th>
            <td>
              This rule allows Gorouter health checks.<br><br>
              <strong>Name</strong>: <code>pcf-allow-http-8080</code><br>
              <strong>Network</strong>: <code>pcf-virt-net</code><br>
              <strong>Allowed protocols and ports</strong>: <code>tcp:8080</code><br>
              <strong>Source filter</strong>: IP ranges<br>
              <strong>Source IP Ranges</strong>: <code>0.0.0.0/0</code><br>
              <strong>Target tags</strong>: <code>router</code>
            </td>
          </tr>
          <tr>
            <th>Rule 5</th>
            <td>
              This rule allows communication between BOSH-deployed jobs.<br><br>
              <strong>Name</strong>: <code>pcf-allow-pas-all</code><br>
              <strong>Network</strong>: <code>pcf-virt-net</code><br>
              <strong>Allowed protocols and ports</strong>: <code>tcp;udp;icmp</code><br>
              <strong>Source filter</strong>: Source tags<br>
              <strong>Target tags</strong>: <code>pcf</code>, <code>pcf-opsman</code>, <code>nat-traverse</code><br>
              <strong>Source tags</strong>: <code>pcf</code>, <code>pcf-opsman</code>, <code>nat-traverse</code>
            </td>
          </tr>
          <tr>
            <th>Rule 6 (Optional)</th>
            <td>
              This rule allows access to the TCP router.<br><br>
              <strong>Name</strong>: <code>pcf-allow-cf-tcp</code><br>
              <strong>Network</strong>: <code>pcf-virt-net</code><br>
              <strong>Source filter</strong>: IP ranges<br>
              <strong>Source IP ranges</strong>: <code>0.0.0.0/0</code><br>
              <strong>Allowed protocols and ports</strong>: <code>tcp:1024-65535</code><br>
              <strong>Target tags</strong>: <code>pcf-cf-tcp</code>
            </td>
          </tr>
          <tr>
            <th>Rule 7 (Optional)</th>
            <td>
              This rule allows access to the SSH proxy.<br><br>
              <strong>Name</strong>: <code>pcf-allow-ssh-proxy</code><br>
              <strong>Network</strong>: <code>pcf-virt-net</code><br>
              <strong>Source filter</strong>: IP ranges<br>
              <strong>Source IP ranges</strong>: <code>0.0.0.0/0</code><br>
              <strong>Allowed protocols and ports</strong>: <code>tcp:2222</code><br>
              <strong>Target tags</strong>: <code>pcf-ssh-proxy</code>, <code>diego-brain</code><br>
            </td>
          </tr>
        </table>
   <p class="note"><strong>Note:</strong> If you want your firewall rules to only permit traffic within your private network, modify the <strong>Source IP Ranges</strong> from the table accordingly.</p>

1. If you are only using your GCP project to deploy Ops Manager, then you can delete the following default firewall rules:
   * `default-allow-http`
   * `default-allow-https`
   * `default-allow-icmp`
   * `default-allow-internal`
   * `default-allow-rdp`
   * `default-allow-ssh`

If you are deploying **<%= vars.pks_product_short%> only**, continue to [Next Steps](#next-steps).

If you are deploying **PAS or other runtimes**, proceed to the following step.


## <a id="dbs"></a> Step 6: Create Database Instance and Databases

### <a id='create-dbs-instance'></a> Create Database Instance

1. For a shared-VPC installation, select the service project in the GCP console. This step and the following steps allocate resources to the service project, not the host project.

1. From the GCP console, select **SQL** and click **CREATE INSTANCE**.

1. Ensure **MySQL** is selected and click **Next**.

1. Under **MySQL**, select instance type **Second Generation**.

1. Click **Configure MySQL** under your choice for instance type: Development, Staging, or Production.

1. Configure the instance as follows:
  * **Instance ID**: `pcf-pas-sql`
  * **Root password**: Set a password for the root user.
  * **Region**: Select the region you specified when creating networks.
  * **Zone**: **Any**.
  * **Configure machine type and storage**:
     * Click **Change** and then select **db-n1-standard-2**.
     * Ensure that **Enable automatic storage increases** is selected. This allows DB storage to grow automatically when space is required.
  * **Enable auto backups and high availability**: Make the following selections:
     * Leave **Automate backups** and **Enable binary logging** selected.
     * Under **High availability**, select the **Create failover replica** checkbox.
  * **Authorize Networks**: Click **Add network** and create a network named `all` that allows traffic from `0.0.0.0/0`.
  <p class="note"><strong>Note:</strong> If you assigned static IP addresses to your NAT instances, you can instead limit access to the database instances by specifying the NAT IP addresses.</p>

1. Click **Create**.

### <a id='create-dbs'></a> Create Databases

1. Navigate to the **Instances** page and select the database instance you just created.

1. Select the **Databases** tab.

1. Click **Create database** to create the following databases:
  * `account`
  * `app_usage_service`
  * `autoscale`
  * `ccdb`
  * `console`
  * `diego`
  * `locket`
  * `networkpolicyserver`
  * `nfsvolume`
  * `notifications`
  * `routing`
  * `silk`
  * `uaa`
  * `credhub`

1. Select the **USERS** tab.

1. Click **Create user account** to create a unique username and password for each database you created above. For **Host name**, select **Allow any host**. You must create a total of fourteen user accounts.

<p class='note'><strong>Note:</strong> Ensure that the networkpolicyserver database user has the <code>ALL PRIVILEGES</code> permission.</p>


## <a id="buckets"></a> Step 7: Create Storage Buckets

1. With your single project or shared-VPC service project selected in the GCP console, select **Storage** > **Browser**.

1. Using **CREATE BUCKET**, create buckets with the following names. For **Default storage class**, select **Multi-Regional**:
  * `pcf-buildpacks`
  * `pcf-droplets`
  * `pcf-packages`
  * `pcf-resources`


## <a id="loadbalancer"></a> Step 8: Create HTTP Load Balancer

For load balancing, you can use a global HTTP load balancer or an internal, regional load balancer with a private IP address.

Single-project, standalone installations typically use a global HTTP load balancer. See [Create HTTP Load Balancer](#http_loadbalancer) for how to set this up.

Shared-VPC installation typically use an internal TCP/UDP load balancer to minimize public IP addresses. See [Create Internal Load Balancer](#internal_loadbalancer) for how to set this up.

### <a id="internal_loadbalancer"></a> Create Internal Load Balancer

To create an internal load balancer for Ops Manager on GCP, do the following.

1. Create an internal-facing TCP/UDP load balancer for each region of your PCF deployment.
<p class="note"><strong>Note</strong>: GCP Internal Load Balancer (iLB) is a regional product. Within the same VPC/network, client VMs in a different region from the iLB cannot access the iLB. See <a href="https://cloud.google.com/load-balancing/docs/internal/setting-up-internal#global_routing_issue">Global Routing Issue</a> in the Google Cloud <em>Setting Up Internal Load Balancing</em> documentation.</p>

1. Assign private IP addresses to the load balancers.

1. After you have deployed Ops Manager, follow instructions in [Create or Update a VM Extension](https://docs.pivotal.io/pivotalcf/<%= product_info['local_product_version'].to_s.sub('.','-') %>/customizing/custom-vm-extensions.html#create-vm-extension) to add a custom VM extension that applies internal load balancing to all VMs deployed by BOSH.
  - For example, the following manifest code adds a VM extension `backend-pool` to PCF VMs:

    ```
vm_extensions:
- name: backend-pool
  cloud_properties:
    ephemeral_external_ip: true
    backend_service:
      name: name-of-backend-service
      scheme: INTERNAL
    ```

### <a id="http_loadbalancer"></a> Create HTTP Load Balancer

To create a global HTTP load balancer for PCF on GCP, do the following:

1. [Create Instance Group](#create-instance-group)
1. [Create Health Check](#create-health-check)
1. [Configure Back End](#config-backend)
1. [Configure Front End](#config-frontend)

#### <a id='create-instance-group'></a> Create Instance Group

1. Navigate to **Compute Engine** > **Instance groups**.

1. Click **CREATE INSTANCE GROUP**.

1. Complete the form as follows:
  * For **Name**, enter `pcf-http-lb`
  * For **Location**, select **Single-zone**.
  * For **Zone**, select the first zone from your region.<br>
    Example: For region `us-west1`, select zone `us-west1-a`.
  * Under **Group type**, select **Unmanaged instance group**.
  * For **Network**, select `pcf-virt-net`.
  * For **Subnetwork**, select the `pcf-pas-subnet-my-gcp-region` subnet that you created previously.
  * Click **Create**.

1. Create a second instance group with the following details:
  * **Name**: `pcf-http-lb`
  * **Location**: **Single-zone**
  * **Zone**: Select the second zone from your region.<br>
    Example: For region `us-west1`, select zone `us-west1-b`.
  * **Group type**: Select **Unmanaged instance group**.
  * **Network**: Select `pcf-virt-net`.
  * **Subnetwork**: Select the `pcf-pas-subnet-my-gcp-region` subnet that you created previously.

1. Create a third instance group with the following details:
  * **Name**: `pcf-http-lb`
  * **Location**: **Single-zone**
  * **Zone**: Select the third zone from your region.<br>
    Example: For region `us-west1`, select zone `us-west1-c`.
  * **Group type**: Select **Unmanaged instance group**.
  * **Network**: Select `pcf-virt-net`.
  * **Subnetwork**: Select the `pcf-pas-subnet-my-gcp-region` subnet that you created previously.

#### <a id='create-health-check'></a> Create Health Check

1. Navigate to **Compute Engine** > **Health checks**.

1. Click **CREATE HEALTH CHECK**.

1. Complete the form as follows:
  * **Name**: `pcf-cf-public`
  * **Port**: `8080`
  * **Request path**: `/health`
  * **Check interval**: `30`
  * **Timeout**: `5`
  * **Healthy threshold**: `10`
  * **Unhealthy threshold**: `2`

1. Click **Create**.

#### <a id='config-backend'></a> Configure Back End

1. Navigate to **Network services** > **Load balancing**.

1. Click **CREATE LOAD BALANCER**.

1. Under **HTTP(S) Load Balancing**, click **Start configuration**.

1. For the **Name**, enter `pcf-global-pcf`.

1. Select **Backend configuration**
  1. From the dropdown, select **Backend services** > **Create a backend service**.
  1. Complete the form as follows:
    * **Name**: `pcf-http-lb-backend`.
    * **Protocol**: `HTTP`.
    * **Named port**: `http`.
    * **Timeout**: `10 seconds`.
    * Under **Backends** > **New backend**, select the **Instance group** that corresponds to the first zone of the multi-zone instance group you created. For example: `pcf-http-lb (us-west1-a)`. Click **Done**.
    * Click **Add backend**, select the **Instance group** that corresponds to the second zone of the multi-zone instance group you created. For example: `pcf-http-lb (us-west1-b)`. Click **Done**.
    * Click **Add backend**, select the **Instance group** that corresponds to the third zone of the multi-zone instance group you created. For example: `pcf-http-lb (us-west1-c)`. Click **Done**.
    * **Health check**: Select the `pcf-cf-public` health check that you created.
    * **Cloud CDN**: Ensure Cloud CDN is disabled.

 1. Click **Create**.

#### <a id='config-frontend'></a> Configure Front End

1. Click **Host and path rules** to populate the default fields and a green check mark.

1. Select **Frontend configuration**, and add the following:
   * **Name**: `pcf-cf-lb-http`
   * **Protocol**: `HTTP`
   * **IP**: Perform the following steps:
       1. Select **Create IP address**.
       1. Enter a **Name** for the new static IP address and an optional description. For example, `pcf-global-pcf`.
       1. Click **Reserve**.
   * **Port**: `80`

1. Click **Add Frontend IP and port** and add the following:
  <p class="note"><strong>Note:</strong> Skip this step if you do not have either a self-signed or trusted SSL certificate.
     When you configure the tile for your chosen runtime, you are given the opportunity to create a new self-signed certificate.
     Upon creating a certificate, you can complete the **Add Frontend IP and port** section.â€©</p>
  * **Name**: `pcf-cf-lb-https`
  * **Protocol**: `HTTPS`
  * **IP address**: Select the `pcf-global-pcf` address you create for the previous **Frontend IP and Port**.
  * **Port**: `443`
  * Select **Create a new certificate**. The **Create a New Certificate** dialog is displayed.
  * In the **Name** field, enter a name for the certificate.
     <%= image_tag "../common/images/gcp/lb_frontend_cert.png" %>
  * In the **Public key certificate** field, copy in the contents of your public certificate, or upload your certificate as a .pem file.
     If the certificate is runtime-generated, copy and paste the generated contents from the runtime's Certificate field into the Ops Manager **Public key certificate** field.
  * In the **Certificate chain** field, enter or upload your certificate chain in the .pem format.
  If you are using a self-signed certificate, such as a PAS or <%= vars.pks_product_short%>-generated certificate, do not enter a value in the **Certificate Chain** field.
  * In the **Private key** field, copy in the contents or upload the .pem file of the private key for the certificate.
  If the certificate is runtime-generated, copy and paste the generated contents from the runtime's Private Key field into the Ops Manager **Private key** field.

1. Review the completed frontend configuration.

1. Click **Review and finalize** to verify your configuration.

1. Click **Create**.


## <a id="tcp_websockets_lb"></a> Step 9: Create TCP WebSockets Load Balancer

The load balancer for tailing logs with WebSockets for PCF on GCP operates on TCP port `443`.

1. From the GCP console, select **Network services > Load balancing > Create load balancer**.

1. Under **TCP Load Balancing**, click **Start configuration**.
  <%= image_tag("../common/images/gcp/create_new_lb.png") %>

1. In the **Create a load balancer** configuration screen, make the following selections:
  * Under **Internet facing or internal only**, select **From Internet to my VMs**.
  * Under **Multiple regions or single region**, select **Single region only**.
  * Under **Connection termination**, select **No (TCP)**.
    <%= image_tag("../common/images/gcp/lb_connection_termination.png") %>

1. Click **Continue**.

1. In the **New TCP load balancer** window, enter `pcf-wss-logs` in the **Name** field.

1. Click **Backend configuration** to configure the **Backend service**:
  <%= image_tag "../common/images/gcp/tcp_websockets_backend.png" %>
  * **Region**: Select the region you used to create the network in [Create a GCP Network with Subnets](#create_network).
  * From the **Health check** dropdown, create a health check with the following details:
      * **Name**: `pcf-gorouter`
      * **Port**: `8080`
      * **Request path**: `/health`
      * **Check interval**: `30`
      * **Timeout**: `5`
      * **Healthy threshold**: `10`
      * **Unhealthy threshold**: `2`
  The **Backend configuration** section shows a green check mark.

1. Click **Frontend configuration** to open its configuration window and complete the fields:
 * **Protocol**: `TCP`
 * **IP**: Perform the following steps:
       1. Select **Create IP address**.
       1. For name **Name** for the new static IP address and an optional description. For example, `pcf-gorouter-wss`.
       1. Click **Reserve**.
 * **Port**: `443`
1. Click **Review and finalize** to verify your configuration.
  <%= image_tag "../common/images/gcp/websockets_lb_finalize.png" %>
1. Click **Create**.


## <a id="ssh_lb"></a> Step 10: Create SSH Proxy Load Balancer

1. From the GCP console, select **Network services > Load balancing > Create load balancer**.

1. Under **TCP Load Balancing**, click **Start configuration**.

1. Under **Internet facing or internal only**, select **From Internet to my VMs**.

1. Under **Connection termination**, select **No (TCP)**.
  <%= image_tag("../common/images/gcp/lb_connection_termination.png") %>

1. Click **Continue**.

1. In the **New TCP load balancer** window, enter `pcf-ssh-proxy` in the **Name** field.

1. Select **Backend configuration**, and enter the following field values:
   * **Region**: Select the region you used to create the network in [Create a GCP Network with Subnet](#create_network).
   * **Backup pool**: `None`
   * **Failover ratio**: `10%`
   * **Health check**: `No health check`
<%= image_tag("../common/images/gcp/ssl_lb_backend_config_complete.png") %>

1. Select **Frontend configuration**, and add the following:
   * **Protocol**: `TCP`
   * **IP**: Perform the following steps:
       1. Select **Create IP address**.
       1. Enter a **Name** for the new static IP address and an optional description. For example, `pcf-ssh-proxy`.
       1. Click **Reserve**.
   * **Port**: `2222`

1. (Optional) Review and finalize your load balancer.

1. Click **Create**.


## <a id="tcp_lb"></a> Step 11: Create Load Balancer for TCP Router

<p class="note"><strong>Note:</strong> This step is optional and only required if you enable TCP routing in your deployment.</p>

To create a load balancer for TCP routing in GCP, do the following:

1. From the GCP console, select **Network services > Load balancing > Create load balancer**.

1. Under **TCP Load Balancing**, click **Start configuration**.

1. Under **Connection termination**, select **No (TCP)**. Click **Continue**.

	<%= image_tag("../common/images/gcp/lb_connection_termination.png") %>

1. On the **New TCP load balancer** screen, enter a unique name for the load balancer in the **Name** field. For example, `pcf-cf-tcp-lb`.

1. Select **Backend configuration**, and enter the following field values:
   * **Region**: Select the region you used to create the network in [Create a GCP Network with Subnet](#create_network).
   * From the **Health check** dropdown, create a health check with the following details:
      * **Name**: `pcf-tcp-lb`
      * **Port**: `80`
      * **Request path**: `/health`
      * **Check interval**: `30`
      * **Timeout**: `5`
      * **Healthy threshold**: `10`
      * **Unhealthy threshold**: `2`
      * Click **Save and continue**.
 <%= image_tag("../common/images/gcp/tcp_lb_backend.png") %>

1. Select **Frontend configuration**, and add the front end IP and port entry as follows:
   * **Protocol**: `TCP`
   * **IP**: Perform the following steps:
       1. Select **Create IP address**.
       1. Enter a **Name** for the new static IP address and an optional description. For example, `pcf-cf-tcp-lb`.
       1. Click **Reserve**.
   * **Port**: `1024-65535`

	<%= image_tag("../common/images/gcp/tcp_lb_frontend.png") %>

1. Click **Review and finalize** to verify your configuration.

1. Click **Create**.


## <a id='cname'></a> Step 12: Add DNS Records for Your Load Balancers

In this step, you redirect queries for your domain to the IP addresses of your load balancers.

1. Locate the static IP addresses of the load balancers you created in [Preparing to Deploy Ops Manager on GCP Manually](./prepare-env-manual.html):
    * An HTTP(S) load balancer named `pcf-global-pcf`
    * A TCP load balancer for WebSockets named `pcf-wss-logs`
    * A TCP load balancer named `pcf-ssh-proxy`
    * A TCP load balancer named `pcf-cf-tcp-lb`
    <p class="note"><strong>Note:</strong> You can locate the static IP address of each load balancer by clicking its name under <strong>Network services > Load balancing</strong> in the GCP console.</p>

1. Log in to the DNS registrar that hosts your domain. Examples of DNS registrars include Network Solutions, GoDaddy, and Register.com.

1. Create **A records** with your DNS registrar that map domain names to the public static IP addresses of the load balancers located above:
  <table border="1" valign="top">
      <tr>
      <th>Create and map this record...</th><th>To the IP of this load balancer</th><th>Required</th>
      </tr>
      <tr>
        <td><code>\*.sys.MY-DOMAIN</code><br>
        Example: <code>\*.sys.example.com</code></td>
        <td><code>pcf-global-pcf</code></td>
        <td>Yes</td>
      </tr>
      <tr>
        <td><code>\*.apps.MY-DOMAIN</code><br>
        Example: <code>\*.apps.example.com</code></td>
        <td><code>pcf-global-pcf</code></td>
        <td>Yes</td>
      </tr>
      <tr>
        <td><code>doppler.sys.MY-DOMAIN</code>
        <br>
        Example: <code>doppler.sys.example.com</code></td>
        <td><code>pcf-wss-logs</code></td>
        <td>Yes</td>
      </tr>
            <tr>
        <td><code>loggregator.sys.MY-DOMAIN</code><br>
        Example: <code>loggregator.sys.example.com</code></td>
        <td><code>pcf-wss-logs</code></td>
        <td>Yes</td>
      </tr>
      <tr>
        <td><code>ssh.sys.MY-DOMAIN</code>
        <br>
        Example: <code>ssh.sys.example.com</code></td>
        <td><code>pcf-ssh-proxy</code></td>
        <td>Yes, to allow SSH access to apps</td>
      </tr>
      <tr>
        <td><code>tcp.MY-DOMAIN</code>
        <br>
        Example: <code>tcp.example.com</code></td>
        <td><code>pcf-cf-tcp-lb</code></td>
        <td>No, only set up if you have enabled the TCP routing feature</td>
      </tr>
    </table>

1. Save changes within the web interface of your DNS registrar.

1. In a terminal window, run the following `dig` command to confirm that you created your A record successfully:

    <pre>dig SUBDOMAIN.EXAMPLE-URL.com</pre>

    Where `SUBDOMAIN.EXAMPLE-URL` is the subdomain for your load balancer. <br><br>

    You should see the A record that you just created:
    <pre class='terminal'>
;; ANSWER SECTION:
xyz.EXAMPLE.COM.      1767    IN  A 203.0.113.1</pre>


## <a id="next-steps"></a> Next Steps

* (Optional) To prepare for deploying either a PAS or <%= vars.pks_product_short%> tile on GCP, you can download the needed runtime tile in advance:
  * To download PAS, log in to [Pivotal Network](https://network.pivotal.io/products/elastic-runtime), select your desired release version, and download **Pivotal Application Service**.
  * To download <%= vars.pks_product_short%>, log in to [Pivotal Network](https://network.pivotal.io/products/pivotal-container-service), select your desired release version, and download **Pivotal Container Service**.

* After initiating the tile download, proceed to the next step, [Deploying Ops Manager on GCP Manually](./deploy-manual.html).
